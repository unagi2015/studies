{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b07aba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from llama_index.core.schema import NodeWithScore, QueryType\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core.postprocessor.types import BaseNodePostprocessor\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from typing import List\n",
    "from llama_index.core.schema import MetadataMode\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92d7eb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023_북한인권보고서.pdf 다운로드 완료\n"
     ]
    }
   ],
   "source": [
    "# 분석할 PDF 파일을 웹에서 다운로드.\n",
    "url = \"https://github.com/llama-index-tutorial/llama-index-tutorial/raw/main/ch07/2023_%EB%B6%81%ED%95%9C%EC%9D%B8%EA%B6%8C%EB%B3%B4%EA%B3%A0%EC%84%9C.pdf\"\n",
    "filename = \"2023_북한인권보고서.pdf\"\n",
    "\n",
    "response = requests.get(url)\n",
    "with open(filename, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "print(f\"{filename} 다운로드 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "067a0536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라마인덱스의 핵심 설정: LLM, 임베딩 모델, 문서 분할 방식을 전역으로 설정\n",
    "Settings.llm = OpenAI(model=\"gpt-4.1\", temperature=0.2)  # GPT-4.1를 언어 모델로 사용\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")  # 임베딩 모델 사용\n",
    "Settings.chunk_size = 300  # 문서를 300자 단위로 분할\n",
    "Settings.chunk_overlap = 100  # 문맥 유지를 위해 청크 간 100자 중복\n",
    "\n",
    "# PDF 문서를 읽고 벡터 인덱스 생성\n",
    "reader = SimpleDirectoryReader(input_files=[\"2023_북한인권보고서.pdf\"])  # PDF 문서 로더\n",
    "documents = reader.load_data()  # 문서에서 텍스트 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c0650d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)  # 추출된 텍스트로 벡터 인덱스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6306cfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentScorer(BaseNodePostprocessor):\n",
    "    # LLM을 사용해 문서의 관련성을 정밀하게 평가하고 점수를 매기는 클래스\n",
    "\n",
    "    def evaluate_document(self, query: str, content: str) -> float:\n",
    "        # LLM을 사용해 문서와 쿼리 간의 의미적 관련성을 1-10점으로 평가\n",
    "        prompt = f\"\"\"\n",
    "        아래 주어진 질문과 문서의 관련성을 평가해주세요.\n",
    "\n",
    "        [평가 기준]\n",
    "        - 문서가 질문에서 요구하는 정보를 직접적으로 포함하면 8-10점  \n",
    "        - 문서가 질문과 관련된 맥락을 포함하지만 직접적인 답이 아니면 4-7점\n",
    "        - 문서가 질문과 거의 관련이 없으면 1-3점\n",
    "        \n",
    "        [주의사항]\n",
    "        - 단순히 비슷한 단어가 등장하는 것은 높은 점수의 근거가 될 수 없습니다\n",
    "        - 질문의 의도와 문맥을 정확히 파악하여 평가해주세요\n",
    "        - 시간, 장소, 수치 등 구체적인 정보의 일치 여부를 중요하게 고려해주세요\n",
    "        \n",
    "        질문: {query}\n",
    "        문서: {content}\n",
    "        \n",
    "        응답은 반드시 다음 JSON 형식이어야 합니다:\n",
    "        {{\"relevance_score\": float}}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            # LLM에 프롬프트를 전송하고 JSON 형식의 응답을 받음\n",
    "            response = Settings.llm.complete(prompt)\n",
    "            # 응답에서 relevance_score 값을 추출\n",
    "            score = json.loads(response.text)[\"relevance_score\"]\n",
    "            # 점수를 float로 변환하여 반환\n",
    "            return float(score)\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {str(e)}\")\n",
    "            return 5.0  # 에러 발생시 중간 점수로 처리하여 시스템 안정성 유지\n",
    "\n",
    "    def _postprocess_nodes(self, nodes: List[NodeWithScore], query: QueryType) -> List[NodeWithScore]:\n",
    "        # 벡터 검색으로 찾은 4개 문서를 LLM으로 재평가하여 최적의 2개 선택\n",
    "        print('\\n=== LLM이 4개의 검색 결과에 대해서 관련성을 평가합니다. ===')\n",
    "        scored_docs = []\n",
    "        for node in nodes:\n",
    "            # 현재 처리 중인 문서 노드에서 순수 텍스트 컨텐츠만 추출\n",
    "            content = node.node.get_content(metadata_mode=MetadataMode.NONE)\n",
    "            # LLM으로 문서 관련성 점수 계산 (1-10 사이 점수)\n",
    "            score = self.evaluate_document(str(query), content)\n",
    "            # 디버깅/모니터링을 위해 각 문서의 내용과 점수를 출력\n",
    "            print(f\"\\nLLM 기반의 평가:\\n{content}\\n=> 점수: {score}\\n\")\n",
    "            # 현재 노드와 계산된 점수를 튜플로 저장\n",
    "            scored_docs.append((node, score))\n",
    "\n",
    "        # 모든 문서를 점수 기준 내림차순으로 정렬하고 상위 2개만 선택하여 반환\n",
    "        ranked_docs = sorted(scored_docs, key=lambda x: x[1], reverse=True)\n",
    "        return [node for node, _ in ranked_docs[:2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6fe37dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticRanker(BaseRetriever):\n",
    "    # 벡터 검색 결과에 LLM 기반 의미적 평가를 적용하여 최적의 문서를 선별하는 시스템\n",
    "\n",
    "    def __init__(self, index, scorer):\n",
    "        # 생성자에서 벡터 검색용 인덱스와 LLM 기반 문서 평가기 인스턴스를 받아 저장\n",
    "        self.index = index  # 벡터 검색용 인덱스\n",
    "        self.scorer = scorer  # LLM 기반 문서 평가기\n",
    "\n",
    "    def _retrieve(self, query: str) -> List[NodeWithScore]:\n",
    "        # 벡터 검색으로 유사도 기반 후보 문서 4개를 추출하고 LLM으로 재평가\n",
    "        vector_results = self.index.as_retriever(similarity_top_k=4).retrieve(query)\n",
    "\n",
    "        # 초기 벡터 검색 결과를 디버깅/분석용으로 출력\n",
    "        print(\"\\n=== 실제 검색 결과 (Top 4) ===\")\n",
    "        for i, node in enumerate(vector_results, 1):\n",
    "            print(f\"\\n검색 문서 {i}:\")\n",
    "            print(node.node.get_content(metadata_mode=MetadataMode.NONE))\n",
    "\n",
    "        # LLM으로 문서들을 재평가하고 재정렬하여 최적의 2개 선택\n",
    "        reranked_results = self.scorer._postprocess_nodes(vector_results, query)\n",
    "\n",
    "        # 최종 선별된 문서를 디버깅/분석용으로 출력\n",
    "        print(\"\\n=== LLM의 리랭킹 결과 (Top 2) ===\")\n",
    "        for i, node in enumerate(reranked_results, 1):\n",
    "            print(f\"\\n검색 문서 {i}:\")\n",
    "            print(node.node.get_content(metadata_mode=MetadataMode.NONE))\n",
    "\n",
    "        return reranked_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e4c8d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "질문: 19년 말 평양시 소재 기업소에서 달마다 배급받은 음식\n",
      "\n",
      "=== 실제 검색 결과 (Top 4) ===\n",
      "\n",
      "검색 문서 1:\n",
      "대체로 합영·합작회사, \n",
      "외화벌이 기관 등 운영이 잘되는 경우였으며, 보수를 달러나 위안\n",
      "화 또는 쌀이나 기름 등 현물로 지급하였다고 한다. 2019년 평양\n",
      "의 외화벌이 사업소에서는 보수 50달러를 월 2회로 나누어 현금으\n",
      "로 지급하였다고 하는 사례가 있었고, 평양 외화벌이 식당에서는 매\n",
      "\n",
      "검색 문서 2:\n",
      "2023 북한인권보고서\n",
      "252\n",
      "며, 배급량의 80%는 강냉이로 쌀은 명절에만 배급되었다는 진술이 \n",
      "있었다. 기업소에서 배급표는 매월 두 차례(7~8일경 및 21~22일경 \n",
      "상·하순) 지급되었고, 거주지 배급소에서 식량으로 바꾸면 되었다고 \n",
      "한다. \n",
      "식량배급이 되더라도 규정에 미치지 못하는 매우 적은 양을 받았\n",
      "던 경우도 많았다.\n",
      "\n",
      "검색 문서 3:\n",
      "외화벌이 기관 등\n",
      "에는 식량배급이 원활하게 이뤄지고 있었다는 증언이 수집되었다. \n",
      "2019년 평양시에서 기업소 운전원으로 일하였던 노동자는 매월 쌀·\n",
      "설탕·기름·야채·돼지고기 등을 배급받아 식량이 부족하지 않았다는 \n",
      "증언과 2019년 중앙당 산하의 기업소에서 매월 쌀 6㎏ 정도, 기름 5\n",
      "ℓ, 설탕 2㎏, 맛내기 2봉지, 돼지고기 2㎏, 닭고기 1마리 정도 받았\n",
      "다는 증언이 있었다.\n",
      "\n",
      "검색 문서 4:\n",
      "세대주가 직장에 다닐 경우 세대주만 직장에서 배급을 받고 \n",
      "가족들은 국가배급소에서 배급을 받습니다. 평양시와 자강도는 대\n",
      "체로 다 줬는데 다른 지역은 배급이 잘 안되고 배급제가 없어졌다는 \n",
      "소리를 들었습니다. ”\n",
      "국가배급의 주기, 양, 곡물의 종류 등에서 평양시와 지방의 차이\n",
      "가 크게 나고 있었다.\n",
      "\n",
      "=== LLM이 4개의 검색 결과에 대해서 관련성을 평가합니다. ===\n",
      "\n",
      "LLM 기반의 평가:\n",
      "대체로 합영·합작회사, \n",
      "외화벌이 기관 등 운영이 잘되는 경우였으며, 보수를 달러나 위안\n",
      "화 또는 쌀이나 기름 등 현물로 지급하였다고 한다. 2019년 평양\n",
      "의 외화벌이 사업소에서는 보수 50달러를 월 2회로 나누어 현금으\n",
      "로 지급하였다고 하는 사례가 있었고, 평양 외화벌이 식당에서는 매\n",
      "=> 점수: 4.0\n",
      "\n",
      "\n",
      "LLM 기반의 평가:\n",
      "2023 북한인권보고서\n",
      "252\n",
      "며, 배급량의 80%는 강냉이로 쌀은 명절에만 배급되었다는 진술이 \n",
      "있었다. 기업소에서 배급표는 매월 두 차례(7~8일경 및 21~22일경 \n",
      "상·하순) 지급되었고, 거주지 배급소에서 식량으로 바꾸면 되었다고 \n",
      "한다. \n",
      "식량배급이 되더라도 규정에 미치지 못하는 매우 적은 양을 받았\n",
      "던 경우도 많았다.\n",
      "=> 점수: 7.0\n",
      "\n",
      "\n",
      "LLM 기반의 평가:\n",
      "외화벌이 기관 등\n",
      "에는 식량배급이 원활하게 이뤄지고 있었다는 증언이 수집되었다. \n",
      "2019년 평양시에서 기업소 운전원으로 일하였던 노동자는 매월 쌀·\n",
      "설탕·기름·야채·돼지고기 등을 배급받아 식량이 부족하지 않았다는 \n",
      "증언과 2019년 중앙당 산하의 기업소에서 매월 쌀 6㎏ 정도, 기름 5\n",
      "ℓ, 설탕 2㎏, 맛내기 2봉지, 돼지고기 2㎏, 닭고기 1마리 정도 받았\n",
      "다는 증언이 있었다.\n",
      "=> 점수: 10.0\n",
      "\n",
      "\n",
      "LLM 기반의 평가:\n",
      "세대주가 직장에 다닐 경우 세대주만 직장에서 배급을 받고 \n",
      "가족들은 국가배급소에서 배급을 받습니다. 평양시와 자강도는 대\n",
      "체로 다 줬는데 다른 지역은 배급이 잘 안되고 배급제가 없어졌다는 \n",
      "소리를 들었습니다. ”\n",
      "국가배급의 주기, 양, 곡물의 종류 등에서 평양시와 지방의 차이\n",
      "가 크게 나고 있었다.\n",
      "=> 점수: 6.0\n",
      "\n",
      "\n",
      "=== LLM의 리랭킹 결과 (Top 2) ===\n",
      "\n",
      "검색 문서 1:\n",
      "외화벌이 기관 등\n",
      "에는 식량배급이 원활하게 이뤄지고 있었다는 증언이 수집되었다. \n",
      "2019년 평양시에서 기업소 운전원으로 일하였던 노동자는 매월 쌀·\n",
      "설탕·기름·야채·돼지고기 등을 배급받아 식량이 부족하지 않았다는 \n",
      "증언과 2019년 중앙당 산하의 기업소에서 매월 쌀 6㎏ 정도, 기름 5\n",
      "ℓ, 설탕 2㎏, 맛내기 2봉지, 돼지고기 2㎏, 닭고기 1마리 정도 받았\n",
      "다는 증언이 있었다.\n",
      "\n",
      "검색 문서 2:\n",
      "2023 북한인권보고서\n",
      "252\n",
      "며, 배급량의 80%는 강냉이로 쌀은 명절에만 배급되었다는 진술이 \n",
      "있었다. 기업소에서 배급표는 매월 두 차례(7~8일경 및 21~22일경 \n",
      "상·하순) 지급되었고, 거주지 배급소에서 식량으로 바꾸면 되었다고 \n",
      "한다. \n",
      "식량배급이 되더라도 규정에 미치지 못하는 매우 적은 양을 받았\n",
      "던 경우도 많았다.\n",
      "\n",
      "최종 답: 2019년 말 평양시 소재 기업소에서 매월 쌀, 설탕, 기름, 야채, 돼지고기 등을 배급받았으며, 구체적으로는 쌀 6kg 정도, 기름 5ℓ, 설탕 2kg, 맛내기 2봉지, 돼지고기 2kg, 닭고기 1마리 정도를 받았다는 증언이 있다.\n"
     ]
    }
   ],
   "source": [
    "# 문서 평가 및 검색 시스템 선언(초기화)\n",
    "scorer = DocumentScorer()  # LLM 기반 문서 평가기 생성\n",
    "ranker = SemanticRanker(index, scorer)  # 벡터 검색과 LLM 평가를 결합한 시스템 생성\n",
    "query_engine = RetrieverQueryEngine(retriever=ranker)  # 최종 질의응답 엔진 생성\n",
    "\n",
    "# 실제 쿼리 실행\n",
    "query = \"19년 말 평양시 소재 기업소에서 달마다 배급받은 음식\"\n",
    "print(f\"\\n질문: {query}\")\n",
    "response = query_engine.query(query)  # 쿼리 실행하여 응답 생성\n",
    "print(f\"\\n최종 답: {response}\")  # 최종 응답 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf542c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.postprocessor import SentenceTransformerRerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fab1a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LlamaIndex의 핵심 설정: LLM, 임베딩 모델, 문서 분할 방식을 전역으로 설정\n",
    "Settings.llm = OpenAI(model=\"gpt-4.1\", temperature=0.2)  # GPT-4.1을 언어 모델로 사용\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")  # 임베딩 모델 사용\n",
    "Settings.chunk_size = 300  # 문서를 300자 단위로 분할\n",
    "Settings.chunk_overlap = 100  # 문맥 유지를 위해 청크 간 100자 중복\n",
    "\n",
    "# PDF 문서를 읽고 벡터 인덱스 생성\n",
    "reader = SimpleDirectoryReader(input_files=[\"2023_북한인권보고서.pdf\"])  # PDF 문서 로더\n",
    "documents = reader.load_data()  # 문서에서 텍스트 추출\n",
    "index = VectorStoreIndex.from_documents(documents)  # 추출된 텍스트로 벡터 인덱스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d777e8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joo\\anaconda3\\envs\\ch07_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 기본 검색 엔진 (리랭킹 없음)\n",
    "basic_query_engine = index.as_query_engine(\n",
    "    similarity_top_k=4\n",
    ")\n",
    "\n",
    "# Reranker 설정\n",
    "reranker = SentenceTransformerRerank(\n",
    "    model=\"BAAI/bge-reranker-v2-m3\",\n",
    "    top_n=2\n",
    ")\n",
    "\n",
    "# 리랭킹이 포함된 검색 엔진\n",
    "rerank_query_engine = index.as_query_engine(\n",
    "    similarity_top_k=4,\n",
    "    node_postprocessors=[reranker]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc9ff07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리랭킹이 포함된 검색 엔진\n",
    "rerank_query_engine = index.as_query_engine(\n",
    "    similarity_top_k=4,\n",
    "    node_postprocessors=[reranker]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9fb1db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 기본 검색 엔진 검색 결과 ===\n",
      "\n",
      "질문: 19년 말 평양시 소재 기업소에서 달마다 배급받은 음식\n",
      "답변: 2019년 말 평양시 소재 기업소에서 매월 쌀 6kg 정도, 기름 5ℓ, 설탕 2kg, 맛내기 2봉지, 돼지고기 2kg, 닭고기 1마리 정도를 배급받았다는 증언이 있다.\n",
      "\n",
      "검색된 문서:\n",
      "\n",
      "검색 문서 1:\n",
      "대체로 합영·합작회사, \n",
      "외화벌이 기관 등 운영이 잘되는 경우였으며, 보수를 달러나 위안\n",
      "화 또는 쌀이나 기름 등 현물로 지급하였다고 한다. 2019년 평양\n",
      "의 외화벌이 사업소에서는 보수 50달러를 월 2회로 나누어 현금으\n",
      "로 지급하였다고 하는 사례가 있었고, 평양 외화벌이 식당에서는 매\n",
      "---\n",
      "\n",
      "검색 문서 2:\n",
      "2023 북한인권보고서\n",
      "252\n",
      "며, 배급량의 80%는 강냉이로 쌀은 명절에만 배급되었다는 진술이 \n",
      "있었다. 기업소에서 배급표는 매월 두 차례(7~8일경 및 21~22일경 \n",
      "상·하순) 지급되었고, 거주지 배급소에서 식량으로 바꾸면 되었다고 \n",
      "한다. \n",
      "식량배급이 되더라도 규정에 미치지 못하는 매우 적은 양을 받았\n",
      "던 경우도 많았다.\n",
      "---\n",
      "\n",
      "검색 문서 3:\n",
      "외화벌이 기관 등\n",
      "에는 식량배급이 원활하게 이뤄지고 있었다는 증언이 수집되었다. \n",
      "2019년 평양시에서 기업소 운전원으로 일하였던 노동자는 매월 쌀·\n",
      "설탕·기름·야채·돼지고기 등을 배급받아 식량이 부족하지 않았다는 \n",
      "증언과 2019년 중앙당 산하의 기업소에서 매월 쌀 6㎏ 정도, 기름 5\n",
      "ℓ, 설탕 2㎏, 맛내기 2봉지, 돼지고기 2㎏, 닭고기 1마리 정도 받았\n",
      "다는 증언이 있었다.\n",
      "---\n",
      "\n",
      "검색 문서 4:\n",
      "세대주가 직장에 다닐 경우 세대주만 직장에서 배급을 받고 \n",
      "가족들은 국가배급소에서 배급을 받습니다. 평양시와 자강도는 대\n",
      "체로 다 줬는데 다른 지역은 배급이 잘 안되고 배급제가 없어졌다는 \n",
      "소리를 들었습니다. ”\n",
      "국가배급의 주기, 양, 곡물의 종류 등에서 평양시와 지방의 차이\n",
      "가 크게 나고 있었다.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# 쿼리 실행\n",
    "query = \"19년 말 평양시 소재 기업소에서 달마다 배급받은 음식\"\n",
    "\n",
    "print(\"=== 기본 검색 엔진 검색 결과 ===\")\n",
    "basic_response = basic_query_engine.query(query)\n",
    "print(f\"\\n질문: {query}\")\n",
    "print(f\"답변: {basic_response.response}\")\n",
    "print(\"\\n검색된 문서:\")\n",
    "for i, node in enumerate(basic_response.source_nodes):\n",
    "    print(f\"\\n검색 문서 {i+1}:\")\n",
    "    print(node.node.get_content())\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0696bd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== 리랭킹 후 검색 결과 ===\n",
      "\n",
      "질문: 19년 말 평양시 소재 기업소에서 달마다 배급받은 음식\n",
      "답변: 2019년 말 평양시 소재 기업소에서 매월 쌀, 설탕, 기름, 야채, 돼지고기 등을 배급받았으며, 구체적으로는 쌀 6kg 정도, 기름 5ℓ, 설탕 2kg, 맛내기 2봉지, 돼지고기 2kg, 닭고기 1마리 정도를 받았다는 증언이 있다.\n",
      "\n",
      "검색된 문서:\n",
      "\n",
      "검색 문서 1:\n",
      "외화벌이 기관 등\n",
      "에는 식량배급이 원활하게 이뤄지고 있었다는 증언이 수집되었다. \n",
      "2019년 평양시에서 기업소 운전원으로 일하였던 노동자는 매월 쌀·\n",
      "설탕·기름·야채·돼지고기 등을 배급받아 식량이 부족하지 않았다는 \n",
      "증언과 2019년 중앙당 산하의 기업소에서 매월 쌀 6㎏ 정도, 기름 5\n",
      "ℓ, 설탕 2㎏, 맛내기 2봉지, 돼지고기 2㎏, 닭고기 1마리 정도 받았\n",
      "다는 증언이 있었다.\n",
      "---\n",
      "\n",
      "검색 문서 2:\n",
      "2023 북한인권보고서\n",
      "252\n",
      "며, 배급량의 80%는 강냉이로 쌀은 명절에만 배급되었다는 진술이 \n",
      "있었다. 기업소에서 배급표는 매월 두 차례(7~8일경 및 21~22일경 \n",
      "상·하순) 지급되었고, 거주지 배급소에서 식량으로 바꾸면 되었다고 \n",
      "한다. \n",
      "식량배급이 되더라도 규정에 미치지 못하는 매우 적은 양을 받았\n",
      "던 경우도 많았다.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n=== 리랭킹 후 검색 결과 ===\")\n",
    "rerank_response = rerank_query_engine.query(query)\n",
    "print(f\"\\n질문: {query}\")\n",
    "print(f\"답변: {rerank_response.response}\")\n",
    "print(\"\\n검색된 문서:\")\n",
    "for i, node in enumerate(rerank_response.source_nodes):\n",
    "    print(f\"\\n검색 문서 {i+1}:\")\n",
    "    print(node.node.get_content())\n",
    "    print(\"---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ch07_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
