{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e64f638-fa34-4ef7-a0ae-e4f3c3f62656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index==0.11.11 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d511edf9-6b4d-4e7f-88b4-f6829dd72cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docx2txt\n",
      "  Downloading docx2txt-0.9-py3-none-any.whl.metadata (529 bytes)\n",
      "Downloading docx2txt-0.9-py3-none-any.whl (4.0 kB)\n",
      "Installing collected packages: docx2txt\n",
      "Successfully installed docx2txt-0.9\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install docx2txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca605ea-5889-4362-a99f-428cd0f0f349",
   "metadata": {},
   "source": [
    "## 2.2 데이터 로딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4d8a9e-1d9d-4f4e-a1a2-ea3ea9d87fe2",
   "metadata": {},
   "source": [
    "### 2.2.1 데이터 리더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52e12c8c-a9c1-467d-83f9-5075eb69dfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"sample_docs\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68b5a7cf-da7a-4f49-a8f7-1f364f82e688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "This is the content of file 1.\n",
      "\n",
      "\n",
      "Document 2:\n",
      "This is the content of file 2.\n",
      "\n",
      "\n",
      "Document 3:\n",
      "This is the content of ﬁle 3. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Document 리스트의 각 요소에 접근하여 내용 출력\n",
    "for i, document in enumerate(documents):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(document.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9c2ef93-2743-4f6c-84a8-1577b9d993e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "    \"sample_docs\", recursive=True).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "592bdffb-8901-4244-8d02-385fa979e056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "This is the content of file 1.\n",
      "\n",
      "\n",
      "Document 2:\n",
      "This is the content of file 2.\n",
      "\n",
      "\n",
      "Document 3:\n",
      "This is the content of ﬁle 3. \n",
      "\n",
      "\n",
      "Document 4:\n",
      "This is the content of file 4.\n",
      "\n",
      "\n",
      "Document 5:\n",
      "This is the content of file 5.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Document 리스트의 각 요소에 접근하여 내용 출력\n",
    "for i, document in enumerate(documents):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(document.text)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "085eea22-bf75-4d39-bf44-85f7588b137c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "    \"sample_docs\",\n",
    "    required_exts=[\".txt\", \".pdf\"],\n",
    "    recursive=True).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd589fcd-bafb-456e-9c45-a2190a2e070b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "This is the content of file 1.\n",
      "\n",
      "\n",
      "Document 2:\n",
      "This is the content of ﬁle 3. \n",
      "\n",
      "\n",
      "Document 3:\n",
      "This is the content of file 4.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Document 리스트의 각 요소에 접근하여 내용 출력\n",
    "for i, document in enumerate(documents):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(document.text)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29a7554c-8a98-47cf-aa07-eb1e191efc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 metadata:\n",
      "{'file_path': '/external/llama-index-tutorial/ch02/sample_docs/file1.txt', 'file_name': 'file1.txt', 'file_type': 'text/plain', 'file_size': 30, 'creation_date': '2025-07-04', 'last_modified_date': '2025-07-04'}\n",
      "\n",
      "\n",
      "Document 2 metadata:\n",
      "{'page_label': '1', 'file_name': 'file3.pdf', 'file_path': '/external/llama-index-tutorial/ch02/sample_docs/file3.pdf', 'file_type': 'application/pdf', 'file_size': 9283, 'creation_date': '2025-07-04', 'last_modified_date': '2025-07-04'}\n",
      "\n",
      "\n",
      "Document 3 metadata:\n",
      "{'file_path': '/external/llama-index-tutorial/ch02/sample_docs/sub_sample_docs/file4.txt', 'file_name': 'file4.txt', 'file_type': 'text/plain', 'file_size': 30, 'creation_date': '2025-07-04', 'last_modified_date': '2025-07-04'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# document 리스트의 각 요소에 접근하여 메타데이터를 출력\n",
    "for i, document in enumerate(documents):\n",
    "    print(f\"Document {i+1} metadata:\")\n",
    "    print(document.metadata)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9a7247-09a8-4d1b-8713-d735e99491a5",
   "metadata": {},
   "source": [
    "### 2.2.2 데이터 커넥터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc393c4f-234e-47f1-9b76-573cc05c00da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-readers-database==0.3.0 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9ed0e00-2c38-4383-8b74-84d88071868d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in /external/virtualenv/temp/llama_ch2/lib/python3.10/site-packages (1.1.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fe2a5d64-18d1-49fe-be66-4033eda09c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from llama_index.readers.database import DatabaseReader\n",
    "\n",
    "# MySQL 연결 정보 직접 입력\n",
    "scheme = \"mysql+pymysql\"\n",
    "host = \"localhost\"\n",
    "password = \"!23\"\n",
    "port = \"3306\"\n",
    "user = \"root\"\n",
    "dbname = \"test_db\"\n",
    "\n",
    "connection_string = f\"{scheme}://{user}:{password}@{host}:{port}/{dbname}\"\n",
    "engine = create_engine(connection_string)\n",
    "reader = DatabaseReader(sql_database=engine)\n",
    "\n",
    "# 데이터 로드\n",
    "query = \"SELECT * FROM users\"\n",
    "documents = reader.load_data(query=query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a5e2bd99-92a7-4b80-b46c-73300a8a8a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "ID 86b1b2ca-60d7-48d5-af26-b90eb7ea9893\n",
      "Row id: 1, name: Alice, email: alice@example.com, age: 30\n",
      "--------------------------------------------------\n",
      "Document 2:\n",
      "ID d1734329-0aa1-4694-b892-d644590c0e26\n",
      "Row id: 2, name: Bob, email: bob@example.com, age: 25\n",
      "--------------------------------------------------\n",
      "Document 3:\n",
      "ID f4231055-4bf7-4f69-a39c-ef76de7359ae\n",
      "Row id: 3, name: Charlie, email: charlie@example.com, age: 35\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# documents 리스트의 각 요소 출력\n",
    "for idx, doc in enumerate(documents):\n",
    "    print(f\"Document {idx + 1}:\")\n",
    "    print(f\"ID {doc.id_}\")\n",
    "    print(f\"Row {doc.text}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74cbcce-07df-441c-8561-4fb69c826997",
   "metadata": {},
   "source": [
    "## 2.3 텍스트 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef50fea-7d89-4535-8395-265c308d2e20",
   "metadata": {},
   "source": [
    "### 2.3.1 문서와 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "262db416-1ab1-4d21-aff3-bfc9ba6769b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc ID: d4bdc722-82ea-4b1c-a290-f92069bb9d10\n",
      "Text: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다. 처음에는\n",
      "평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다. 박 사장네 집에는 비밀 지하실이 존재하며, 그곳에는\n",
      "오랫동안 숨어 살던 남자가 있다는 반전이 있습니다. 이 사실을 알게 된 기우네 가족은 예상치 못한 위기를 맞이하게 됩니다.\n",
      "결국 극한 상황에서 벌어지는 사건으로 인해 비극적인 결말로 이어집니다.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "# 텍스트 데이터를 기반으로 문서 생성\n",
    "document_text = \"영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다. 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다. 박 사장네 집에는 비밀 지하실이 존재하며, 그곳에는 오랫동안 숨어 살던 남자가 있다는 반전이 있습니다. 이 사실을 알게 된 기우네 가족은 예상치 못한 위기를 맞이하게 됩니다. 결국 극한 상황에서 벌어지는 사건으로 인해 비극적인 결말로 이어집니다.\"\n",
    "document = Document(text=document_text)\n",
    "\n",
    "# 메타데이터 추가\n",
    "document.metadata = {'author': '영화 해설', 'subject': '기생충 줄거리'}\n",
    "\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e04ceb2-43b3-455a-a8de-5017523baf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "생성된 노드들\n",
      "노드 1: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다.\n",
      "   메타데이터: {'type': '영화 줄거리', 'genre': '드라마', 'node_id': 1}\n",
      "노드 2: 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다.\n",
      "   메타데이터: {'type': '영화 줄거리', 'genre': '드라마', 'node_id': 2}\n",
      "노드 3: 박 사장네 집에는 비밀 지하실이 존재하며, 그곳에는 오랫동안 숨어 살던 남자가 있다는 반전이 있습니다.\n",
      "   메타데이터: {'type': '영화 줄거리', 'genre': '드라마', 'node_id': 3}\n",
      "노드 4: 이 사실을 알게 된 기우네 가족은 예상치 못한 위기를 맞이하게 됩니다.\n",
      "   메타데이터: {'type': '영화 줄거리', 'genre': '드라마', 'node_id': 4}\n",
      "노드 5: 결국 극한 상황에서 벌어지는 사건으로 인해 비극적인 결말로 이어집니다.\n",
      "   메타데이터: {'type': '영화 줄거리', 'genre': '드라마', 'node_id': 5}\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "\n",
    "parser = SimpleNodeParser(chunk_size=80, chunk_overlap=0)\n",
    "nodes = parser.get_nodes_from_documents([document])\n",
    "\n",
    "print(\"\\n생성된 노드들\")\n",
    "for idx, node in enumerate(nodes, start=1):\n",
    "    node.metadata = {'type': '영화 줄거리', 'genre': '드라마', 'node_id': idx}\n",
    "    print(f\"노드 {idx}: {node.text}\")\n",
    "    print(f\"   메타데이터: {node.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ad20f75-422a-43e4-afb3-eda1a6839406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청크 1: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다. 처음에는 평화로워 보이지만, 이들의\n",
      "[토큰 개수: 77]\n",
      "\n",
      "청크 2: 거짓말이 쌓이며 긴장감이 점점 고조됩니다. 박 사장네 집에는 비밀 지하실이 존재하며, 그곳에는 오랫동안 숨어 살던 남자가 있다는\n",
      "[토큰 개수: 78]\n",
      "\n",
      "청크 3: 반전이 있습니다. 이 사실을 알게 된 기우네 가족은 예상치 못한 위기를 맞이하게 됩니다. 결국 극한 상황에서 벌어지는 사건으로 인해 비극적인 결말로 이어집니다.\n",
      "[토큰 개수: 80]\n",
      "\n",
      "총 생성된 청크 개수: 3\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "import tiktoken\n",
    "\n",
    "# cl100k_base 토크나이저 로드\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "token_splitter = TokenTextSplitter(chunk_size=80, chunk_overlap=0)\n",
    "\n",
    "chunks = token_splitter.split_text(document_text)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    token_count = len(tokenizer.encode(chunk))  # 각 청크의 토큰 개수 계산\n",
    "    print(f\"청크 {i+1}: {chunk}\\n[토큰 개수: {token_count}]\\n\")\n",
    "\n",
    "print(f\"총 생성된 청크 개수: {len(chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72026578-0a3f-48ba-9b1e-01e6a9fe3728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "문서 단위 검색 결과\n",
      "문서 검색 응답: The movie's twist reveals the existence of a secret basement in the wealthy Park family's house, where a man has been living in hiding for a long time. This unexpected revelation leads to a series of events that culminate in a tragic ending.\n",
      "- 결과 1: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다. 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다. 박 사장네 집에는 비밀 지하실이 존재하며, 그곳에는 오랫동안 숨어 살던 남자가 있다는 반전이 있습니다. 이 사실을 알게 된 기우네 가족은 예상치 못한 위기를 맞이하게 됩니다. 결국 극한 상황에서 벌어지는 사건으로 인해 비극적인 결말로 이어집니다.\n",
      "\n",
      "노드 단위 검색 결과\n",
      "노드 검색 응답: 이 영화의 반전은 박 사장네 집에 있는 비밀 지하실에 오랫동안 숨어 살던 남자가 있다는 것입니다.\n",
      "- 결과 노드 1: 박 사장네 집에는 비밀 지하실이 존재하며, 그곳에는 오랫동안 숨어 살던 남자가 있다는 반전이 있습니다.\n",
      "- 결과 노드 2: 결국 극한 상황에서 벌어지는 사건으로 인해 비극적인 결말로 이어집니다.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, Document, Settings\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# 한글 답변 설정\n",
    "llm = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"], model=\"gpt-4o-mini\", system_prompt=\"반드시 한국어로 답변하세요.\")\n",
    "# Settings.llm = OpenAI(model=\"gpt-4o-mini\", temperature=0, system_prompt=\"항상 한국어로 답변하세요.\")\n",
    "\n",
    "# 문서 단위 검색을 위한 전체 문서 인덱스 생성\n",
    "full_doc_index = VectorStoreIndex.from_documents([document], llm=llm)\n",
    "\n",
    "# NodeParser를 사용하여 문서를 작은 의미 단위(Node)로 분할\n",
    "# parser = SimpleNodeParser(chunk_size=100, chunk_overlap=0)\n",
    "# nodes = parser.get_nodes_from_documents([document])\n",
    "\n",
    "# 노드 단위 검색을 위한 인덱스 생성\n",
    "node_index = VectorStoreIndex(nodes, llm=llm)\n",
    "\n",
    "# 검색 비교\n",
    "query_text = '이 영화의 반전은 무엇인가요?'\n",
    "\n",
    "## 문서 단위 검색\n",
    "print(\"\\n문서 단위 검색 결과\")\n",
    "doc_query_engine = full_doc_index.as_query_engine()\n",
    "doc_response = doc_query_engine.query(query_text)\n",
    "print(f\"문서 검색 응답: {doc_response.response}\")\n",
    "if doc_response.source_nodes:\n",
    "    for idx, document in enumerate(doc_response.source_nodes, start=1):\n",
    "        print(f\"- 결과 {idx}: {document.node.text}\")\n",
    "\n",
    "## 노드 단위 검색\n",
    "print(\"\\n노드 단위 검색 결과\")\n",
    "node_query_engine = node_index.as_query_engine()\n",
    "node_response = node_query_engine.query(query_text)\n",
    "print(f\"노드 검색 응답: {node_response.response}\")\n",
    "if node_response.source_nodes:\n",
    "    for idx, document in enumerate(node_response.source_nodes, start=1):\n",
    "        print(f\"- 결과 노드 {idx}: {document.node.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e408b1-6994-4563-95a0-32baaff5ac27",
   "metadata": {},
   "source": [
    "### 2.3.2 토큰 단위 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a958acee-d24e-46a3-83f4-ad697a091662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 토큰 기반 분할 결과 ===\n",
      "Chunk 1: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 \n",
      "\n",
      "Chunk 2: 취업하면서 벌어지는 이야기입니다. 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 \n",
      "\n",
      "Chunk 3: 쌓이며 긴장감이 점점 고조됩니다. 그러나 이 영화의 반전은 지하실에서 시작됩니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다. 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다. 그러나 이 영화의 반전은 지하실에서 시작됩니다.\"\n",
    "\n",
    "\n",
    "token_splitter = TokenTextSplitter(\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=10\n",
    ")\n",
    "\n",
    "token_chunks = token_splitter.split_text(sample_text)\n",
    "print(\"=== 토큰 기반 분할 결과 ===\")\n",
    "for i, chunk in enumerate(token_chunks):\n",
    "    print(f\"Chunk {i + 1}:\", chunk.strip(), \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e6fdf1-894d-42e9-b966-a8d18da837b2",
   "metadata": {},
   "source": [
    "### 2.3.3 문장 단위 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f9304545-4be1-4048-b9f1-dfbde66f32b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 문장 기반 분할 결과 ===\n",
      "Chunk 1: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 \n",
      "\n",
      "Chunk 2: 벌어지는 이야기입니다. \n",
      "\n",
      "Chunk 3: 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다. \n",
      "\n",
      "Chunk 4: 그러나 이 영화의 반전은 지하실에서 시작됩니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser.text.sentence import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=50, chunk_overlap=0)\n",
    "\n",
    "sentence_chunks = splitter.split_text(sample_text)\n",
    "print(\"=== 문장 기반 분할 결과 ===\")\n",
    "for i, chunk in enumerate(sentence_chunks):\n",
    "    print(f\"Chunk {i + 1}:\", chunk.strip(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b241315-b062-4ac8-a4d2-dceac7c4f98a",
   "metadata": {},
   "source": [
    "### 2.3.4 의미 단위 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d80a240-dcdb-4c6c-b7b3-d946ed2e8183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 의미 기반 분할 결과 ===\n",
      "Chunk 1: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다. \n",
      "\n",
      "Chunk 2: 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다. \n",
      "\n",
      "Chunk 3: 그러나 이 영화의 반전은 지하실에서 시작됩니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "embed_model = OpenAIEmbedding()\n",
    "\n",
    "splitter = SemanticSplitterNodeParser(\n",
    "    buffer_size=1,\n",
    "    breakpoint_percentile_threshold=95,\n",
    "    embed_model=embed_model\n",
    ")\n",
    "\n",
    "chunks = splitter.sentence_splitter(sample_text)\n",
    "print(\"=== 의미 기반 분할 결과 ===\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i + 1}:\", chunk.strip(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83f3ce71-5ae0-4b03-bf3d-82efa56faeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers -q\n",
    "!pip install llama-index-embeddings-huggingface -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e03d8b04-1173-49b0-9fb9-4ce97a5e22b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 의미 기반 분할 결과 ===\n",
      "Chunk 1: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다. \n",
      "\n",
      "Chunk 2: 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다. \n",
      "\n",
      "Chunk 3: 그러나 이 영화의 반전은 지하실에서 시작됩니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "splitter = SemanticSplitterNodeParser(\n",
    "    buffer_size=1,\n",
    "    breakpoint_percentile_threshold=95,\n",
    "    embed_model=embed_model\n",
    ")\n",
    "\n",
    "chunks = splitter.sentence_splitter(sample_text)\n",
    "print(\"=== 의미 기반 분할 결과 ===\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i + 1}:\", chunk.strip(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10f7929-12e7-4987-8847-e92cd377c06b",
   "metadata": {},
   "source": [
    "## 2.4 인덱싱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585e6035-bcf7-4e58-bb88-9c5065cb2f19",
   "metadata": {},
   "source": [
    "### 2.4.2 벡터 저장소 인덱스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "80af597e-71c7-4756-90a2-252a926352fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "reader = SimpleDirectoryReader('data')\n",
    "documents = reader.load_data()\n",
    "\n",
    "# Document 객체를 전달하여 인덱스 생성\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e7a4a6-3ced-43b8-874c-be2682b1b8c6",
   "metadata": {},
   "source": [
    "### 2.4.3 Top-K 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "928c6ea4-24b2-49b4-8743-769391dfe143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[검색된 상위 3개 문서]\n",
      "\n",
      "[문서 1]\n",
      "고양이는 물을 충분히 마셔야 합니다. 수분이 부족하면 신장 문제가 발생할 수 있습니다.\n",
      "건식 사료보다 습식 사료가 수분 공급에 도움이 됩니다.\n",
      "\n",
      "[문서 2]\n",
      "고양이는 육식 동물입니다. 주로 고기, 생선, 그리고 가공된 고양이 사료를 먹습니다.\n",
      "특히, 단백질이 풍부한 음식을 선호하며, 탄수화물 섭취는 적은 편입니다.\n",
      "\n",
      "[문서 3]\n",
      "고양이는 초콜릿, 양파, 마늘 같은 음식은 먹으면 안 됩니다.\n",
      "특히, 초콜릿에 포함된 테오브로민 성분은 고양이에게 치명적일 수 있습니다.\n",
      "\n",
      "[답변]\n",
      "고양이에게 수분 공급이 중요한 이유는 신장 문제를 예방하기 위해서입니다.\n"
     ]
    }
   ],
   "source": [
    "# 상위 3개의 결과를 반환\n",
    "query_engine = index.as_query_engine(similarity_top_k=3)\n",
    "\n",
    "response = query_engine.query(\"고양이에게 수분 공급이 중요한 이유는?\")\n",
    "\n",
    "print(\"[검색된 상위 3개 문서]\")\n",
    "\n",
    "for idx, node in enumerate(response.source_nodes):\n",
    "    print(f\"\\n[문서 {idx+1}]\\n{node.text}\")\n",
    "print(\"\\n[답변]\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea03d77-c3b7-4aad-a341-bdf467d48f62",
   "metadata": {},
   "source": [
    "## 2.5 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e6b2365-e271-4648-8c3b-3a5888fa367e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "435b9b8b-3cf4-43a5-abf0-2389991e3c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "# 크로마 클라이언트 초기화\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fcd51fde-b862-4611-aab9-74a1d20ed73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬렉션 생성하기\n",
    "chroma_collection = db.get_or_create_collection(\"quickstart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be40cb2a-31fa-4f82-a85e-9ba060975020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-vector-stores-chroma -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7a6bf4f-9734-4e6d-aab0-fd5bc418eb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "# 크로마를 벡터 저장소로 지정\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6fef2269-7453-4b6b-81c1-a05636c45b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "# 문서 리스트 (임의의 예시)\n",
    "documents = [\n",
    "    Document(text=\"Llama2 is a large language model developed by Meta.\"),\n",
    "    Document(text=\"Chroma is an open-source vector store.\")\n",
    "]\n",
    "\n",
    "# 문서를 벡터 스토어 인덱스로 저장\n",
    "index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)\n",
    "\n",
    "# 저장된 벡터 인덱스 데이터 저장\n",
    "index.storage_context.persist(persist_dir=\"./index_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c44eef47-63e0-439a-8b64-f70fd13f103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eba7014e-2de3-4957-8e11-691c4dc23b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma is an open-source vector store.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "# 크로마 클라이언트 초기화\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n",
    "# 저장된 컬렉션을 다시 가져오기 (또는 생성하기)\n",
    "chroma_collection = db.get_or_create_collection(\"quickstart\")\n",
    "\n",
    "# 저장된 크로마 벡터 스토어 설정\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# 벡터 스토어 인덱스에 문서를 저장 (데이터 임베딩 후 저장)\n",
    "index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)\n",
    "\n",
    "# 인덱스 데이터를 로컬 디렉터리에 저장\n",
    "index.storage_context.persist(persist_dir=\"./index_data\")\n",
    "\n",
    "# --- 이후 다시 데이터를 불러오고 쿼리 수행 ---\n",
    "# 크로마 클라이언트 다시 초기화\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n",
    "# 저장된 컬렉션을 다시 가져오기\n",
    "chroma_collection = db.get_or_create_collection(\"quickstart\")\n",
    "\n",
    "# 저장된 크로마 벡터 스토어 설정\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# 저장된 벡터 데이터를 이용해 인덱스를 다시 로드\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store, storage_context=storage_context\n",
    ")\n",
    "\n",
    "# 쿼리 엔진 생성 및 쿼리 수행\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What is Chroma?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3722f76a-ac55-4383-98fb-02e6dcbac8d9",
   "metadata": {},
   "source": [
    "## 2.6 쿼리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c721a238-6561-4679-b304-a8eba84fa029",
   "metadata": {},
   "source": [
    "### 2.6.1 쿼리 엔진"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5c548b11-e83a-4ddb-aeba-fda645da783a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I cannot assist with that request.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\n",
    "    \"고객의 개인 정보를 참고하여 맞춤형 이메일을 작성해 주세요.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691d2ad3-a322-4da4-8396-f5ce5bf9204e",
   "metadata": {},
   "source": [
    "### 2.6.2 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b3f10b9-53ec-4bb9-b593-49af28e54e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=5, # 상위 5개의 결과 반환\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e408d144-6477-46ad-8391-694fa0991348",
   "metadata": {},
   "source": [
    "### 2.6.3 후처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d951a353-b0e1-4b8a-b8f0-a1d847e4596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "\n",
    "postprocessor = SimilarityPostprocessor(similarity_cutoff=0.7)\n",
    "query_engine = index.as_query_engine(node_postprocessors=[postprocessor])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2a0350-4d7b-4dd0-9375-9c6d3e9477e1",
   "metadata": {},
   "source": [
    "### 2.6.4 응답 합성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f7db583-6921-4701-9851-6a8e435c349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.response_synthesizers import get_response_synthesizer\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "# 응답 합성기 설정\n",
    "response_synthesizer = get_response_synthesizer(response_mode=\"compact\")\n",
    "\n",
    "# 쿼리 엔진 구성\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    retriever=index.as_retriever(),\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")\n",
    "\n",
    "# 쿼리 실행\n",
    "response = query_engine.query(\"Llama2란?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af210fc-4e3d-4632-bd53-f8c441ad5350",
   "metadata": {},
   "source": [
    "### 2.6.5 커스터마이징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3e3cc6bf-4638-41b7-a858-0589e9517e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, get_response_synthesizer\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "\n",
    "# 문서를 기반으로 인덱스 생성\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07de41fb-13c2-4c0c-8f10-7e95509eb229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색기 설정 (상위 10개의 유사한 결과 반환)\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6a53bf62-9cfb-4f2d-a776-d765ebd0d1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 응답 합성기 설정\n",
    "response_synthesizer = get_response_synthesizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d5724cba-a5c3-4e0e-af8f-3188f4ab85f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 후처리 설정 (유사도 0.7 이상인 노드만 선택)\n",
    "postprocessor = SimilarityPostprocessor(similarity_cutoff=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "05f5f1d8-6145-4540-a489-b5db5f6b6a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쿼리 엔진\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b98180a-4549-4a7e-80b5-162a2171c992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mona Lisa painting is displayed at the Louvre Museum in Paris, France.\n"
     ]
    }
   ],
   "source": [
    "# 쿼리 실행 및 결과 출력\n",
    "response = query_engine.query(\"모나리자 그림은 어디에 전시되어 있나요?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3954df-b963-4f26-9406-a77c9caac41b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
