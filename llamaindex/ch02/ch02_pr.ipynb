{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc63739e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index==0.11.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.11.11)\n",
      "Collecting llama-index-llms-ollama\n",
      "  Using cached llama_index_llms_ollama-0.8.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama-index-embeddings-huggingface\n",
      "  Using cached llama_index_embeddings_huggingface-0.6.1-py3-none-any.whl.metadata (458 bytes)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.1.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting jupyter\n",
      "  Using cached jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.4.0,>=0.3.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index==0.11.11) (0.3.4)\n",
      "Requirement already satisfied: llama-index-cli<0.4.0,>=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index==0.11.11) (0.3.1)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index==0.11.11) (0.11.23)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.3.0,>=0.2.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index==0.11.11) (0.2.5)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index==0.11.11) (0.6.0)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index==0.11.11) (0.9.48.post4)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.3.0,>=0.2.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index==0.11.11) (0.2.16)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index==0.11.11) (0.2.3)\n",
      "Requirement already satisfied: llama-index-program-openai<0.3.0,>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index==0.11.11) (0.2.0)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.3.0,>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index==0.11.11) (0.2.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.3.0,>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index==0.11.11) (0.2.2)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index==0.11.11) (0.3.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index==0.11.11) (3.9.2)\n",
      "INFO: pip is looking at multiple versions of llama-index-llms-ollama to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-index-llms-ollama\n",
      "  Using cached llama_index_llms_ollama-0.7.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached llama_index_llms_ollama-0.7.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached llama_index_llms_ollama-0.7.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached llama_index_llms_ollama-0.7.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached llama_index_llms_ollama-0.7.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached llama_index_llms_ollama-0.6.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached llama_index_llms_ollama-0.6.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "INFO: pip is still looking at multiple versions of llama-index-llms-ollama to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached llama_index_llms_ollama-0.6.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached llama_index_llms_ollama-0.5.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached llama_index_llms_ollama-0.5.5-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached llama_index_llms_ollama-0.5.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached llama_index_llms_ollama-0.5.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached llama_index_llms_ollama-0.5.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached llama_index_llms_ollama-0.5.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached llama_index_llms_ollama-0.5.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached llama_index_llms_ollama-0.4.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached llama_index_llms_ollama-0.4.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached llama_index_llms_ollama-0.4.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached llama_index_llms_ollama-0.3.6-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting ollama>=0.3.0 (from llama-index-llms-ollama)\n",
      "  Using cached ollama-0.6.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting huggingface-hub>=0.19.0 (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface)\n",
      "  Using cached huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
      "INFO: pip is looking at multiple versions of llama-index-embeddings-huggingface to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-index-embeddings-huggingface\n",
      "  Using cached llama_index_embeddings_huggingface-0.6.0-py3-none-any.whl.metadata (458 bytes)\n",
      "  Using cached llama_index_embeddings_huggingface-0.5.5-py3-none-any.whl.metadata (458 bytes)\n",
      "  Using cached llama_index_embeddings_huggingface-0.5.4-py3-none-any.whl.metadata (458 bytes)\n",
      "  Using cached llama_index_embeddings_huggingface-0.5.3-py3-none-any.whl.metadata (767 bytes)\n",
      "  Using cached llama_index_embeddings_huggingface-0.5.2-py3-none-any.whl.metadata (767 bytes)\n",
      "  Using cached llama_index_embeddings_huggingface-0.5.1-py3-none-any.whl.metadata (767 bytes)\n",
      "  Using cached llama_index_embeddings_huggingface-0.5.0-py3-none-any.whl.metadata (767 bytes)\n",
      "INFO: pip is still looking at multiple versions of llama-index-embeddings-huggingface to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached llama_index_embeddings_huggingface-0.4.0-py3-none-any.whl.metadata (767 bytes)\n",
      "  Using cached llama_index_embeddings_huggingface-0.3.1-py3-none-any.whl.metadata (718 bytes)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.9.0-cp311-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.7.2-cp311-cp311-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.16.2-cp311-cp311-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers) (12.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/mk/Library/Python/3.11/lib/python/site-packages (from sentence-transformers) (4.15.0)\n",
      "Collecting notebook (from jupyter)\n",
      "  Using cached notebook-7.4.7-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jupyter-console (from jupyter)\n",
      "  Using cached jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting nbconvert (from jupyter)\n",
      "  Using cached nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: ipykernel in /Users/mk/Library/Python/3.11/lib/python/site-packages (from jupyter) (7.0.1)\n",
      "Collecting ipywidgets (from jupyter)\n",
      "  Using cached ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting jupyterlab (from jupyter)\n",
      "  Using cached jupyterlab-4.4.9-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2025.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/mk/Library/Python/3.11/lib/python/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.3)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.5)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface)\n",
      "  Using cached hf_xet-1.1.10-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.13.1)\n",
      "Requirement already satisfied: openai>=1.14.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-agent-openai<0.4.0,>=0.3.4->llama-index==0.11.11) (1.109.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (2.0.44)\n",
      "Requirement already satisfied: dataclasses-json in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (1.2.0)\n",
      "Requirement already satisfied: httpx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/mk/Library/Python/3.11/lib/python/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (3.5)\n",
      "Requirement already satisfied: numpy<2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (2.12.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (0.12.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (1.17.3)\n",
      "Requirement already satisfied: llama-cloud>=0.1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index==0.11.11) (0.1.19)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index==0.11.11) (2.2.3)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index==0.11.11) (4.14.2)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index==0.11.11) (4.3.1)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index==0.11.11) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-readers-llama-parse>=0.3.0->llama-index==0.11.11) (0.6.21)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk>3.8.1->llama-index==0.11.11) (8.3.0)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk>3.8.1->llama-index==0.11.11) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk>3.8.1->llama-index==0.11.11) (2025.9.18)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: appnope>=0.1.2 in /Users/mk/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/mk/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/mk/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter) (1.8.17)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Users/mk/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter) (9.6.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in /Users/mk/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/mk/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter) (5.9.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/mk/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter) (0.1.7)\n",
      "Requirement already satisfied: psutil>=5.7 in /Users/mk/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter) (7.1.0)\n",
      "Requirement already satisfied: pyzmq>=25 in /Users/mk/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in /Users/mk/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter) (6.5.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /Users/mk/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets->jupyter)\n",
      "  Using cached widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets->jupyter)\n",
      "  Using cached jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /Users/mk/Library/Python/3.11/lib/python/site-packages (from jupyter-console->jupyter) (3.0.52)\n",
      "Requirement already satisfied: pygments in /Users/mk/Library/Python/3.11/lib/python/site-packages (from jupyter-console->jupyter) (2.19.2)\n",
      "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter)\n",
      "  Using cached async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter)\n",
      "  Using cached jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter)\n",
      "  Using cached jupyter_server-2.17.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter)\n",
      "  Using cached jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting notebook-shim>=0.2 (from jupyterlab->jupyter)\n",
      "  Using cached notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jupyterlab->jupyter) (80.9.0)\n",
      "Collecting bleach!=5.0.0 (from bleach[css]!=5.0.0->nbconvert->jupyter)\n",
      "  Using cached bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: defusedxml in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Collecting jupyterlab-pygments (from nbconvert->jupyter)\n",
      "  Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nbconvert->jupyter) (3.0.3)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert->jupyter)\n",
      "  Using cached mistune-3.1.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert->jupyter)\n",
      "  Using cached nbclient-0.10.2-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting nbformat>=5.7 (from nbconvert->jupyter)\n",
      "  Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter)\n",
      "  Using cached pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.22.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama-index==0.11.11) (2.8)\n",
      "Collecting webencodings (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting tinycss2<1.5,>=1.1.0 (from bleach[css]!=5.0.0->nbconvert->jupyter)\n",
      "  Using cached tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (4.11.0)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (1.0.9)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (0.16.0)\n",
      "Requirement already satisfied: decorator in /Users/mk/Library/Python/3.11/lib/python/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /Users/mk/Library/Python/3.11/lib/python/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/mk/Library/Python/3.11/lib/python/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/mk/Library/Python/3.11/lib/python/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.9.0)\n",
      "Requirement already satisfied: stack_data in /Users/mk/Library/Python/3.11/lib/python/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mk/Library/Python/3.11/lib/python/site-packages (from jupyter-client>=8.0.0->ipykernel->jupyter) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/mk/Library/Python/3.11/lib/python/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.5.0)\n",
      "Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached argon2_cffi-25.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting prometheus-client>=0.9 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached prometheus_client-0.23.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting websocket-client>=1.7 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached websocket_client-1.9.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting babel>=2.10 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached json5-0.12.1-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting jsonschema>=4.18.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.21 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.3.0->llama-index==0.11.11) (0.6.21)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat>=5.7->nbconvert->jupyter)\n",
      "  Using cached fastjsonschema-2.21.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index==0.11.11) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index==0.11.11) (0.11.1)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index==0.11.11) (1.3.1)\n",
      "Requirement already satisfied: wcwidth in /Users/mk/Library/Python/3.11/lib/python/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.14)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (3.2.4)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (3.26.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index==0.11.11) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index==0.11.11) (2025.2)\n",
      "Collecting argon2-cffi-bindings (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached argon2_cffi_bindings-25.1.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/mk/Library/Python/3.11/lib/python/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.5)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached rpds_py-0.27.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached python_json_logger-4.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-cloud-services>=0.6.21->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.3.0->llama-index==0.11.11) (1.1.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/mk/Library/Python/3.11/lib/python/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mk/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->jupyter-client>=8.0.0->ipykernel->jupyter) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/mk/Library/Python/3.11/lib/python/site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/mk/Library/Python/3.11/lib/python/site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/mk/Library/Python/3.11/lib/python/site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (0.2.3)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rfc3987-syntax>=1.1.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached rfc3987_syntax-1.1.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=24.6.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached webcolors-24.11.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting cffi>=1.0.1 (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached cffi-2.0.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.6 kB)\n",
      "Collecting pycparser (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Collecting lark>=1.2.2 (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached lark-1.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Downloading arrow-1.4.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Using cached llama_index_llms_ollama-0.3.6-py3-none-any.whl (5.9 kB)\n",
      "Using cached llama_index_embeddings_huggingface-0.3.1-py3-none-any.whl (8.6 kB)\n",
      "Using cached sentence_transformers-5.1.1-py3-none-any.whl (486 kB)\n",
      "Using cached jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
      "Using cached huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "Using cached ollama-0.6.0-py3-none-any.whl (14 kB)\n",
      "Using cached torch-2.9.0-cp311-none-macosx_11_0_arm64.whl (74.5 MB)\n",
      "Using cached transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "Using cached ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Using cached jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Using cached jupyterlab-4.4.9-py3-none-any.whl (12.3 MB)\n",
      "Using cached nbconvert-7.16.6-py3-none-any.whl (258 kB)\n",
      "Using cached notebook-7.4.7-py3-none-any.whl (14.3 MB)\n",
      "Using cached scikit_learn-1.7.2-cp311-cp311-macosx_12_0_arm64.whl (8.6 MB)\n",
      "Using cached scipy-1.16.2-cp311-cp311-macosx_14_0_arm64.whl (20.9 MB)\n",
      "Using cached async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
      "Using cached bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "Using cached hf_xet-1.1.10-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Using cached jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n",
      "Using cached jupyter_server-2.17.0-py3-none-any.whl (388 kB)\n",
      "Using cached jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
      "Using cached jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Using cached mistune-3.1.4-py3-none-any.whl (53 kB)\n",
      "Using cached nbclient-0.10.2-py3-none-any.whl (25 kB)\n",
      "Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Using cached notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Using cached pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Using cached safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl (432 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl (2.9 MB)\n",
      "Using cached widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Using cached argon2_cffi-25.1.0-py3-none-any.whl (14 kB)\n",
      "Using cached babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
      "Using cached fastjsonschema-2.21.2-py3-none-any.whl (24 kB)\n",
      "Using cached json5-0.12.1-py3-none-any.whl (36 kB)\n",
      "Using cached jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Using cached jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
      "Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Using cached prometheus_client-0.23.1-py3-none-any.whl (61 kB)\n",
      "Using cached Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "Using cached terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "Using cached tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Using cached websocket_client-1.9.0-py3-none-any.whl (82 kB)\n",
      "Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Using cached python_json_logger-4.0.0-py3-none-any.whl (15 kB)\n",
      "Using cached referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Using cached rpds_py-0.27.1-cp311-cp311-macosx_11_0_arm64.whl (353 kB)\n",
      "Using cached argon2_cffi_bindings-25.1.0-cp39-abi3-macosx_11_0_arm64.whl (31 kB)\n",
      "Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Using cached cffi-2.0.0-cp311-cp311-macosx_11_0_arm64.whl (180 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached rfc3987_syntax-1.1.0-py3-none-any.whl (8.0 kB)\n",
      "Using cached webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
      "Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Using cached uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Downloading arrow-1.4.0-py3-none-any.whl (68 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached lark-1.3.0-py3-none-any.whl (113 kB)\n",
      "Using cached pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "Installing collected packages: webencodings, mpmath, fastjsonschema, widgetsnbextension, websocket-client, webcolors, uri-template, tinycss2, threadpoolctl, terminado, sympy, send2trash, scipy, safetensors, rpds-py, rfc3986-validator, rfc3339-validator, python-json-logger, pycparser, prometheus-client, pandocfilters, overrides, mistune, lark, jupyterlab_widgets, jupyterlab-pygments, jsonpointer, json5, hf-xet, fqdn, filelock, bleach, babel, async-lru, torch, scikit-learn, rfc3987-syntax, referencing, jupyter-server-terminals, huggingface-hub, cffi, arrow, tokenizers, ollama, jsonschema-specifications, isoduration, ipywidgets, argon2-cffi-bindings, transformers, llama-index-llms-ollama, jupyter-console, jsonschema, argon2-cffi, sentence-transformers, nbformat, nbclient, llama-index-embeddings-huggingface, jupyter-events, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, jupyter\n",
      "Successfully installed argon2-cffi-25.1.0 argon2-cffi-bindings-25.1.0 arrow-1.4.0 async-lru-2.0.5 babel-2.17.0 bleach-6.2.0 cffi-2.0.0 fastjsonschema-2.21.2 filelock-3.20.0 fqdn-1.5.1 hf-xet-1.1.10 huggingface-hub-0.35.3 ipywidgets-8.1.7 isoduration-20.11.0 json5-0.12.1 jsonpointer-3.0.0 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 jupyter-1.1.1 jupyter-console-6.6.3 jupyter-events-0.12.0 jupyter-lsp-2.3.0 jupyter-server-2.17.0 jupyter-server-terminals-0.5.3 jupyterlab-4.4.9 jupyterlab-pygments-0.3.0 jupyterlab-server-2.27.3 jupyterlab_widgets-3.0.15 lark-1.3.0 llama-index-embeddings-huggingface-0.3.1 llama-index-llms-ollama-0.3.6 mistune-3.1.4 mpmath-1.3.0 nbclient-0.10.2 nbconvert-7.16.6 nbformat-5.10.4 notebook-7.4.7 notebook-shim-0.2.4 ollama-0.6.0 overrides-7.7.0 pandocfilters-1.5.1 prometheus-client-0.23.1 pycparser-2.23 python-json-logger-4.0.0 referencing-0.37.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rfc3987-syntax-1.1.0 rpds-py-0.27.1 safetensors-0.6.2 scikit-learn-1.7.2 scipy-1.16.2 send2trash-1.8.3 sentence-transformers-5.1.1 sympy-1.14.0 terminado-0.18.1 threadpoolctl-3.6.0 tinycss2-1.4.0 tokenizers-0.22.1 torch-2.9.0 transformers-4.57.1 uri-template-1.3.0 webcolors-24.11.1 webencodings-0.5.1 websocket-client-1.9.0 widgetsnbextension-4.0.14\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index==0.11.11 llama-index-llms-ollama llama-index-embeddings-huggingface sentence-transformers jupyter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e289be26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docx2txt\n",
      "  Using cached docx2txt-0.9-py3-none-any.whl.metadata (529 bytes)\n",
      "Using cached docx2txt-0.9-py3-none-any.whl (4.0 kB)\n",
      "Installing collected packages: docx2txt\n",
      "Successfully installed docx2txt-0.9\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2958096a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validate_default' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'validate_default' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "Ignoring wrong pointing object 6 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "This is the content of file 1.\n",
      "\n",
      "\n",
      "Document 2:\n",
      "This is the content of ﬁle 3. \n",
      "\n",
      "\n",
      "Document 3:\n",
      "This is the content of file 4.\n",
      "\n",
      "\n",
      "Metadata 1:\n",
      "{'file_path': '/Users/mk/repo/llamaindex/ch02/sample_docs/file1.txt', 'file_name': 'file1.txt', 'file_type': 'text/plain', 'file_size': 30, 'creation_date': '2025-07-06', 'last_modified_date': '2025-10-19'}\n",
      "\n",
      "\n",
      "Metadata 2:\n",
      "{'page_label': '1', 'file_name': 'file3.pdf', 'file_path': '/Users/mk/repo/llamaindex/ch02/sample_docs/file3.pdf', 'file_type': 'application/pdf', 'file_size': 9283, 'creation_date': '2025-07-06', 'last_modified_date': '2025-10-19'}\n",
      "\n",
      "\n",
      "Metadata 3:\n",
      "{'file_path': '/Users/mk/repo/llamaindex/ch02/sample_docs/sub_sample_docs/file4.txt', 'file_name': 'file4.txt', 'file_type': 'text/plain', 'file_size': 30, 'creation_date': '2025-07-06', 'last_modified_date': '2025-10-19'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "## 로딩.각종 파일\n",
    "documents = SimpleDirectoryReader('sample_docs', recursive=True, required_exts=[\".txt\", \".pdf\"]).load_data()\n",
    "\n",
    "# Document 리스트의 각 요소에 접근하여 내용 출력\n",
    "for i, document in enumerate(documents):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(document.text)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Document 리스트의 각 요소에 접근하여 내용 출력\n",
    "for i, document in enumerate(documents):\n",
    "    print(f\"Metadata {i+1}:\")\n",
    "    print(document.metadata)\n",
    "    print(\"\\n\")\n",
    "\n",
    "## 로딩.커네터(DB연결)\n",
    "# 1.DATABASE 생성\n",
    "# CREATE DATABASE IF NOT EXISTS test_db;\n",
    "# USE test_db;\n",
    "\n",
    "# 2.users 테이블 생성\n",
    "# CREATE TABLE IF NOT EXISTS users (\n",
    "#     id INT PRIMARY KEY,\n",
    "#     name VARCHAR(50),\n",
    "#     email VARCHAR(100),\n",
    "#     age INT\n",
    "# );\n",
    "# 3.데이터 삽입\n",
    "# INSERT INTO users (id, name, email, age) VALUES\n",
    "# (1, 'Alice', 'alice@example.com', 30),\n",
    "# (2, 'Bob', 'bob@example.com', 25),\n",
    "# (3, 'Charlie', 'charlie@example.com', 35);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "625cd036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymysql\n",
      "  Downloading pymysql-1.1.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading pymysql-1.1.2-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymysql\n",
      "Successfully installed pymysql-1.1.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30773a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index==0.11.11\n",
      "  Using cached llama_index-0.11.11-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-readers-database==0.3.0\n",
      "  Using cached llama_index_readers_database-0.3.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting llama-index-agent-openai<0.4.0,>=0.3.4 (from llama-index==0.11.11)\n",
      "  Using cached llama_index_agent_openai-0.3.4-py3-none-any.whl.metadata (728 bytes)\n",
      "Collecting llama-index-cli<0.4.0,>=0.3.1 (from llama-index==0.11.11)\n",
      "  Using cached llama_index_cli-0.3.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.12.0,>=0.11.10 (from llama-index==0.11.11)\n",
      "  Using cached llama_index_core-0.11.23-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.3.0,>=0.2.4 (from llama-index==0.11.11)\n",
      "  Using cached llama_index_embeddings_openai-0.2.5-py3-none-any.whl.metadata (686 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.3.0 (from llama-index==0.11.11)\n",
      "  Using cached llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index==0.11.11)\n",
      "  Using cached llama_index_legacy-0.9.48.post4-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llama-index-llms-openai<0.3.0,>=0.2.9 (from llama-index==0.11.11)\n",
      "  Using cached llama_index_llms_openai-0.2.16-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 (from llama-index==0.11.11)\n",
      "  Using cached llama_index_multi_modal_llms_openai-0.2.3-py3-none-any.whl.metadata (729 bytes)\n",
      "Collecting llama-index-program-openai<0.3.0,>=0.2.0 (from llama-index==0.11.11)\n",
      "  Using cached llama_index_program_openai-0.2.0-py3-none-any.whl.metadata (766 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.3.0,>=0.2.0 (from llama-index==0.11.11)\n",
      "  Using cached llama_index_question_gen_openai-0.2.0-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.3.0,>=0.2.0 (from llama-index==0.11.11)\n",
      "  Using cached llama_index_readers_file-0.2.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.3.0 (from llama-index==0.11.11)\n",
      "  Using cached llama_index_readers_llama_parse-0.5.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index==0.11.11)\n",
      "  Using cached nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "INFO: pip is looking at multiple versions of llama-index-readers-database to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[31mERROR: Cannot install llama-index-readers-database==0.3.0 and llama-index==0.11.11 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "The conflict is caused by:\n",
      "    llama-index 0.11.11 depends on llama-index-core<0.12.0 and >=0.11.10\n",
      "    llama-index-readers-database 0.3.0 depends on llama-index-core<0.13.0 and >=0.12.0\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
      "\n",
      "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --force-reinstall \\\n",
    "llama-index==0.11.11 \\\n",
    "llama-index-readers-database==0.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55a721b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: llama-index-core\n",
      "Version: 0.11.11\n",
      "Summary: Interface between LLMs and your data\n",
      "Home-page: https://llamaindex.ai\n",
      "Author: Jerry Liu\n",
      "Author-email: jerry@llamaindex.ai\n",
      "License: MIT\n",
      "Location: /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages\n",
      "Requires: aiohttp, dataclasses-json, deprecated, dirtyjson, fsspec, httpx, nest-asyncio, networkx, nltk, numpy, pillow, pydantic, PyYAML, requests, SQLAlchemy, tenacity, tiktoken, tqdm, typing-extensions, typing-inspect, wrapt\n",
      "Required-by: llama-cloud-services, llama-index, llama-index-agent-openai, llama-index-cli, llama-index-embeddings-huggingface, llama-index-embeddings-openai, llama-index-indices-managed-llama-cloud, llama-index-llms-ollama, llama-index-llms-openai, llama-index-multi-modal-llms-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index-readers-database, llama-index-readers-file, llama-index-readers-llama-parse\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show llama-index-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d941106c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "id: 1, name: Alice, email: alice@example.com, age: 30\n",
      "\n",
      "\n",
      "Document 2:\n",
      "id: 2, name: Bob, email: bob@example.com, age: 25\n",
      "\n",
      "\n",
      "Document 3:\n",
      "id: 3, name: Charlie, email: charlie@example.com, age: 35\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from llama_index.readers.database import DatabaseReader\n",
    "\n",
    "# MySQL 연결 정보 직접 입력\n",
    "scheme = \"mysql+pymysql\"\n",
    "host = \"localhost\"\n",
    "password = \"\"\n",
    "port = \"3306\"\n",
    "user = \"root\"\n",
    "dbname = \"test_db\"\n",
    "\n",
    "connection_string = f\"{scheme}://{user}:{password}@{host}:{port}/{dbname}\"\n",
    "engine = create_engine(connection_string)\n",
    "reader = DatabaseReader(sql_database=engine)\n",
    "\n",
    "# 데이터 로드\n",
    "query = \"SELECT * FROM users\"\n",
    "documents = reader.load_data(query=query)\n",
    "\n",
    "# Document 리스트의 각 요소에 접근하여 내용 출력\n",
    "for i, document in enumerate(documents):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    # print(f\"ID: {document.id}\")\n",
    "    print(document)\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
